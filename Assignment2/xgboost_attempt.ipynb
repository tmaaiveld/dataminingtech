{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import xgboost as xgb\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "from xgboostextension import XGBRanker\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying some paths\n",
    "path = r\"C:\\Users\\janse\\OneDrive\\Bureaublad\\Master\\Data Mining Techniques\\Assignment 2\"\n",
    "testpath = os.path.join(path, 'test_set_VU_DM.csv')\n",
    "trainpath = os.path.join(path, 'training_set_VU_DM.csv')\n",
    "samplepath = os.path.join(path, 'train_sample.csv')\n",
    "resultpath = os.path.join(path, 'result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train_main\n",
    "def reload_train():\n",
    "    train_main = pd.read_csv(trainpath)\n",
    "    train_main.date_time = pd.to_datetime(train_main.date_time)\n",
    "    return train_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_main = reload_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4958347 entries, 0 to 4958346\n",
      "Data columns (total 54 columns):\n",
      "srch_id                        int64\n",
      "date_time                      datetime64[ns]\n",
      "site_id                        int64\n",
      "visitor_location_country_id    int64\n",
      "visitor_hist_starrating        float64\n",
      "visitor_hist_adr_usd           float64\n",
      "prop_country_id                int64\n",
      "prop_id                        int64\n",
      "prop_starrating                int64\n",
      "prop_review_score              float64\n",
      "prop_brand_bool                int64\n",
      "prop_location_score1           float64\n",
      "prop_location_score2           float64\n",
      "prop_log_historical_price      float64\n",
      "position                       int64\n",
      "price_usd                      float64\n",
      "promotion_flag                 int64\n",
      "srch_destination_id            int64\n",
      "srch_length_of_stay            int64\n",
      "srch_booking_window            int64\n",
      "srch_adults_count              int64\n",
      "srch_children_count            int64\n",
      "srch_room_count                int64\n",
      "srch_saturday_night_bool       int64\n",
      "srch_query_affinity_score      float64\n",
      "orig_destination_distance      float64\n",
      "random_bool                    int64\n",
      "comp1_rate                     float64\n",
      "comp1_inv                      float64\n",
      "comp1_rate_percent_diff        float64\n",
      "comp2_rate                     float64\n",
      "comp2_inv                      float64\n",
      "comp2_rate_percent_diff        float64\n",
      "comp3_rate                     float64\n",
      "comp3_inv                      float64\n",
      "comp3_rate_percent_diff        float64\n",
      "comp4_rate                     float64\n",
      "comp4_inv                      float64\n",
      "comp4_rate_percent_diff        float64\n",
      "comp5_rate                     float64\n",
      "comp5_inv                      float64\n",
      "comp5_rate_percent_diff        float64\n",
      "comp6_rate                     float64\n",
      "comp6_inv                      float64\n",
      "comp6_rate_percent_diff        float64\n",
      "comp7_rate                     float64\n",
      "comp7_inv                      float64\n",
      "comp7_rate_percent_diff        float64\n",
      "comp8_rate                     float64\n",
      "comp8_inv                      float64\n",
      "comp8_rate_percent_diff        float64\n",
      "click_bool                     int64\n",
      "gross_bookings_usd             float64\n",
      "booking_bool                   int64\n",
      "dtypes: datetime64[ns](1), float64(34), int64(19)\n",
      "memory usage: 2.0 GB\n"
     ]
    }
   ],
   "source": [
    "train_main.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulate_comp_scores(train_df):    \n",
    "    # Cumulative competitor scores\n",
    "\n",
    "    cols = [col for col in train_df.columns if col.endswith('rate_percent_diff')]\n",
    "    cols2 = [col for col in train_df.columns if col.endswith('_rate')]\n",
    "    cols3 = [col for col in train_df.columns if col.endswith('_inv')]\n",
    "\n",
    "    df = train_df[cols.extend(cols2).extend(cols3).extend(['prop_id'])]\n",
    "    df['comp_rate_percent_diff_cumm'] = 0\n",
    "\n",
    "    for col1, col2, col3 in zip(cols, cols2, cols3):\n",
    "        df['comp_rate_percent_diff_cumm'] += df[col1].fillna(0) * df[col2].fillna(0) * (1 - df[col3].fillna(0))\n",
    "        \n",
    "    df = train2.drop(cols, axis=1)\n",
    "    df = train2.drop(cols2, axis=1)\n",
    "    df = train2.drop(cols3, axis=1)\n",
    "    return df\n",
    "\n",
    "def average_prop_score(train_df):\n",
    "    cols = ['prop_id', 'price_usd', 'prop_starrating', 'prop_review_score', 'prop_brand_bool', 'prop_location_score1', 'prop_location_score2']\n",
    "    df = train_df[cols]\n",
    "    df['prop_location_score2'] = df['prop_location_score2'].fillna(df.prop_location_score2.mean())\n",
    "    return df.groupby('prop_id').agg('mean').reset_index()\n",
    "\n",
    "class search_clusters:\n",
    "    def __init__(self, n_clusters, searches):\n",
    "        kmean = KMeans(n_clusters=n_clusters)\n",
    "        kmean.fit(searches)\n",
    "        self.clusters = kmean\n",
    "    def assign(self, search_terms):\n",
    "        return self.clusters.predict(search_terms)\n",
    "    \n",
    "def cluster_srch_ids(train_main, one_hot = False, cluster_amount=30):    \n",
    "    train_df = train_main\n",
    "    \n",
    "    cols = [x for x in train_df.columns if x.startswith('srch_')]\n",
    "    df = train_df[cols].drop('srch_query_affinity_score', axis=1)\n",
    "    \n",
    "     \n",
    "    groups = search_clusters(cluster_amount, df.drop_duplicates().drop(['srch_id','srch_destination_id'], axis=1))\n",
    "\n",
    "    clusters = pd.DataFrame()\n",
    "    clusters['search_group'] = groups.assign(train_df[cols].drop(['srch_id','srch_destination_id', 'srch_query_affinity_score'], axis=1))    \n",
    "    clusters['srch_id'] = train_df['srch_id']\n",
    "    clusters['prop_id'] = train_df['prop_id']\n",
    "    \n",
    "    if one_hot:        \n",
    "        clusters = pd.get_dummies(clusters, columns=['search_group'])\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def rate(row, mean_rate):\n",
    "    if row['srch_id'] < 20:\n",
    "        return mean_rate\n",
    "    else:\n",
    "        return row['click_bool']\n",
    "    \n",
    "def avg_click_rate(train_main):\n",
    "    prop_click_rate = train_main[['prop_id','click_bool', 'srch_id']].groupby('prop_id').agg({'click_bool' : 'mean', 'srch_id': 'count'}).reset_index()\n",
    "    mean_rate = prop_click_rate.click_bool.mean()\n",
    "    prop_click_rate['click_rate'] = prop_click_rate.apply(lambda x: rate(x, mean_rate), axis=1)\n",
    "    return prop_click_rate[['prop_id', 'click_rate']]\n",
    "\n",
    "def split_sets(df, test_size = 0.2, shuffle=False, downsample=False):\n",
    "    '''\n",
    "        Returns: X_train, X_test, Y_train, Y_test\n",
    "    '''\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size, shuffle=shuffle) \n",
    "    \n",
    "    if downsample:\n",
    "        df_train = downsample(df_train)\n",
    "    \n",
    "    X_train = df_train.drop(['click_bool','booking_bool'] , axis=1)\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "    X_test = df_test.drop(['click_bool','booking_bool'] , axis=1)    \n",
    "    X_test = X_test.fillna(X_test.mean())\n",
    "    \n",
    "    Y_train = df_train.click_rate\n",
    "    Y_test = df_test.click_rate\n",
    "    \n",
    "    target_train = df_train.click_bool + 4 * df_train.booking_bool\n",
    "    target_test = df_test.click_bool + 4 * df_test.booking_bool    \n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test, target_train, target_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gxboost_ranker(X_train, Y_train, lr = 0.1, n_estimators=50, max_depth=6, objective='rank:ndcg'):\n",
    "    \n",
    "    group_train = X_train.srch_id.values\n",
    "\n",
    "    X = X_train.drop(['srch_id', 'prop_id'], axis=1).values\n",
    "    X = np.concatenate([group_train[:,None], X], axis=1)\n",
    "\n",
    "    Y = Y_train\n",
    "\n",
    "    model = XGBRanker(n_estimators=n_estimators, learning_rate=lr, subsample=0.7, max_depth=max_depth, objective=objective)\n",
    "    model.fit(X, Y, verbose=2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_ranking_SVM():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_test, pred, target_test):\n",
    "    prop_srch = X_test[['srch_id', 'prop_id']]\n",
    "    prop_srch['value'] = pred\n",
    "    prop_srch['actual'] = target_test.values\n",
    "    eval_ndcg(prop_srch, 'srch_id', 'value','actual', n=5000)\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not idcg:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / idcg\n",
    "\n",
    "def eval_ndcg(df, srch_id_col, predict_col, value_col, n=9999999999999999):\n",
    "    df = df.sort_values([srch_id_col, predict_col], ascending=False)\n",
    "    k = 5\n",
    "    ndcgs = []\n",
    "    for i, srchid in enumerate(df[srch_id_col].unique()):\n",
    "        if i == n:\n",
    "            break\n",
    "        if i % 10000 == 0 and i != 0:\n",
    "            print(i)\n",
    "            print(np.mean(ndcgs))\n",
    "        r = df[df[srch_id_col] == srchid][value_col]\n",
    "        ndcgs.append(ndcg_at_k(r,k))\n",
    "\n",
    "    print(np.mean(ndcgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(train_main):\n",
    "    # load initial dataframe\n",
    "    # Select several features that don't need to be changed\n",
    "    df = train_main[['prop_id', 'srch_id', 'position', 'promotion_flag', 'orig_destination_distance', 'random_bool', 'click_bool','booking_bool']]\n",
    "    \n",
    "    # cluster the type of search (one-hot encoded)\n",
    "    df = df.merge(cluster_srch_ids(train_main, one_hot = True), on=['srch_id', 'prop_id'])\n",
    "    \n",
    "    # add average click rate of property\n",
    "    df = df.merge(avg_click_rate(train_main), on='prop_id')\n",
    "    \n",
    "    df = df.merge(average_prop_score(train_main), on='prop_id')\n",
    "    print('Features engineered done')\n",
    "    return df\n",
    "\n",
    "def train_and_test(df):\n",
    "    X_train, X_test, Y_train, Y_test, target_train, target_test = split_sets(df)\n",
    "    \n",
    "    \n",
    "    model = train_gxboost_ranker(X_train, Y_train)\n",
    "    \n",
    "    group_test = X_test.srch_id.values\n",
    "    X_t = X_test.drop(['srch_id', 'prop_id'], axis=1).values\n",
    "    X_t = np.concatenate([group_test[:,None], X_t], axis=1)\n",
    "    \n",
    "    pred = model.predict(X_t)\n",
    "    print('Training done')\n",
    "    \n",
    "    evaluate(X_test, pred, target_test)\n",
    "    print('Evaluated')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features engineered done\n"
     ]
    }
   ],
   "source": [
    "df = feature_eng(train_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n",
      "0.10999612931361298\n",
      "Evaluated\n"
     ]
    }
   ],
   "source": [
    "train_and_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(row, mean_rate):\n",
    "    if row['srch_id'] < 20:\n",
    "        return mean_rate\n",
    "    else:\n",
    "        return row['click_bool']\n",
    "    \n",
    "def avg_click_rate(train_main):\n",
    "    prop_click_rate = train_main[['prop_id','click_bool', 'srch_id']].groupby('prop_id').agg({'click_bool' : 'mean', 'srch_id': 'count'}).reset_index()\n",
    "    mean_rate = prop_click_rate.click_bool.mean()\n",
    "    prop_click_rate['click_rate'] = prop_click_rate.apply(lambda x: rate(x, mean_rate), axis=1)\n",
    "    return prop_click_rate[['prop_id', 'click_rate']]\n",
    "\n",
    "#prop_srch.sort_values(['srch_id','value'], ascending=[True, False]).head(100)\n",
    "avg_rates = avg_click_rate(train_main)\n",
    "print(avg_rates.head())\n",
    "prop_srch = prop_srch.merge(avg_rates, on='prop_id', how='outer')\n",
    "prop_srch['value2'] = prop_srch['value'] * prop_srch['click_rate']\n",
    "eval_ndcg(prop_srch, 'srch_id', 'value2','actual', n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        104.77\n",
       "6938      88.37\n",
       "12605    126.00\n",
       "21958    139.00\n",
       "30512    109.00\n",
       "Name: price_usd, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_main[train_main.prop_id == 893].price_usd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

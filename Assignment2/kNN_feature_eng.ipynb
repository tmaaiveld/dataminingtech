{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying some paths\n",
    "path = r\"C:\\Users\\Tommy\\Documents\\GitHub\\dataminingtech\\Assignment2\\vu-dmt-2assignment\"\n",
    "testpath = os.path.join(path, 'test_set_VU_DM.csv')\n",
    "trainpath = os.path.join(path, 'training_set_VU_DM.csv')\n",
    "samplepath = os.path.join(path, 'train_sample.csv')\n",
    "resultpath = os.path.join(path, 'result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train_main\n",
    "# made a function for quick reusability during development\n",
    "def reload_train():\n",
    "    train_main = pd.read_csv(trainpath)\n",
    "    train_main.date_time = pd.to_datetime(train_main.date_time)\n",
    "    return train_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_main = reload_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_prop_score(train_df):\n",
    "    cols = ['prop_id', 'price_usd', 'prop_starrating', 'prop_review_score', 'prop_brand_bool', 'prop_location_score1', 'prop_location_score2']\n",
    "    df = train_df[cols]\n",
    "    df['prop_location_score2'] = df['prop_location_score2'].fillna(df.prop_location_score2.mean())\n",
    "    return df.groupby('prop_id').agg('mean').reset_index()\n",
    "\n",
    "def rate(row, mean_rate):\n",
    "    if row['srch_id'] < 20:\n",
    "        return mean_rate\n",
    "    else:\n",
    "        return row['click_bool']\n",
    "    \n",
    "def avg_click_rate(train_main):\n",
    "    prop_click_rate = train_main[['prop_id','click_bool', 'srch_id']].groupby('prop_id').agg({'click_bool' : 'mean', 'srch_id': 'count'}).reset_index()\n",
    "    mean_rate = prop_click_rate.click_bool.mean()\n",
    "    prop_click_rate['click_rate'] = prop_click_rate.apply(lambda x: rate(x, mean_rate), axis=1)\n",
    "    return prop_click_rate[['prop_id', 'click_rate']]\n",
    "\n",
    "def split_sets(df, test_size = 0.2, shuffle=False, downsample=False):\n",
    "    '''\n",
    "        Returns: X_train, X_test, Y_train, Y_test\n",
    "    '''\n",
    "    df_train, df_test = train_test_split(df.sort_values('srch_id'), test_size=test_size, shuffle=shuffle) \n",
    "    \n",
    "    if downsample:\n",
    "        df_train = downsample(df_train)\n",
    "    \n",
    "    X_train = df_train.drop(['click_bool','booking_bool'] , axis=1)\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "    X_test = df_test.drop(['click_bool','booking_bool'] , axis=1)    \n",
    "    X_test = X_test.fillna(X_test.mean())\n",
    "    \n",
    "    Y_train = df_train.click_bool + df_train.booking_bool * 4\n",
    "    Y_test = df_test.click_bool + df_train.booking_bool * 4\n",
    "    \n",
    "    target_train = df_train.click_bool + 4 * df_train.booking_bool\n",
    "    target_test = df_test.click_bool + 4 * df_test.booking_bool    \n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test, target_train, target_test\n",
    "\n",
    "def cumulate_comp_scores(train_df):    \n",
    "    # Cumulative competitor scores\n",
    "\n",
    "    cols = [col for col in train_df.columns if col.endswith('rate_percent_diff')]\n",
    "    cols2 = [col for col in train_df.columns if col.endswith('_rate')]\n",
    "    cols3 = [col for col in train_df.columns if col.endswith('_inv')]\n",
    "\n",
    "    df = train_df[cols.extend(cols2).extend(cols3).extend(['prop_id'])]\n",
    "    df['comp_rate_percent_diff_cumm'] = 0\n",
    "\n",
    "    for col1, col2, col3 in zip(cols, cols2, cols3):\n",
    "        df['comp_rate_percent_diff_cumm'] += df[col1].fillna(0) * df[col2].fillna(0) * (1 - df[col3].fillna(0))\n",
    "        \n",
    "    df = train2.drop(cols, axis=1)\n",
    "    df = train2.drop(cols2, axis=1)\n",
    "    df = train2.drop(cols3, axis=1)\n",
    "    return df\n",
    "\n",
    "def avg_prop_features(train_main, test_main = None, predict_phase=False):\n",
    "    cols = [\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
    "       'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance', 'random_bool']\n",
    "    df = train_main[cols].groupby('prop_id').agg(['mean', 'std']) # median?\n",
    "    \n",
    "    if predict_phase:\n",
    "        df = df.merge(test_main[cols + ['srch_id']], on='prop_id')\n",
    "    else:\n",
    "        df = df.merge(train_main[cols + ['srch_id']], on='prop_id')   \n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(train_main):\n",
    "\n",
    "    df = train_main[['prop_id', 'srch_id','date_time', 'click_bool', 'booking_bool']]        \n",
    "    df = df.merge(avg_prop_features(train_main), on=['prop_id', 'srch_id'])    \n",
    "    df = df.fillna(df.mean())\n",
    "    return df.sort_values(['prop_id', 'srch_id'], ascending=[True, False])\n",
    "\n",
    "def test_eng(test_main, train_main):\n",
    "    df = avg_prop_features(train_main, test_main=test_main, predict_phase=True)  \n",
    "    df = df.fillna(df.mean())\n",
    "    return df.sort_values(['srch_id', 'prop_id'], ascending=[True, False])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main dataset\n",
    "df = feature_eng(train_main)\n",
    "df_train = df[df.date_time < '2013-05-30']\n",
    "df_test = df[df.date_time >= '2013-05-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not idcg:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / idcg\n",
    "\n",
    "def eval_ndcg(df, srch_id_col, predict_col, value_col, n=9999999999999999):\n",
    "    df = df.sort_values([srch_id_col, predict_col], ascending=False)\n",
    "    k = 5\n",
    "    ndcgs = []\n",
    "    for i, srchid in enumerate(df[srch_id_col].unique()):\n",
    "        if i == n:\n",
    "            break\n",
    "        if i % 10000 == 0 and i != 0:\n",
    "            print(i)\n",
    "            print(np.mean(ndcgs))\n",
    "        r = df[df[srch_id_col] == srchid][value_col]\n",
    "        ndcgs.append(ndcg_at_k(r,k))\n",
    "\n",
    "    print(np.mean(ndcgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['srch_id', 'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window', 'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool', 'srch_query_affinity_score', 'prop_country_id', 'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool', 'prop_location_score1', 'prop_location_score2', 'prop_log_historical_price', 'promotion_flag', 'random_bool', 'click_bool', 'booking_bool']\n"
     ]
    }
   ],
   "source": [
    "# select columns\n",
    "cols = [x for x in train_main.columns if x.startswith('srch_')]\n",
    "cols.extend([x for x in train_main.columns if x.startswith('prop_')])\n",
    "cols.extend(['promotion_flag', 'random_bool', 'click_bool', 'booking_bool'])\n",
    "#cols.extend(['price_usd','orig_destination_distance', 'promotion_flag'])\n",
    "print(cols)\n",
    "\n",
    "X = df[cols].fillna(0)\n",
    "y = df.click_bool + 4 * train_main.booking_bool\n",
    "X = X.drop(['click_bool','booking_bool'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  \n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=40)  \n",
    "classifier.fit(X_train, y_train)  \n",
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "0.12050288069333226\n",
      "20000\n",
      "0.12015395844716527\n",
      "30000\n",
      "0.12060896001984102\n",
      "40000\n",
      "0.11985276404280648\n",
      "50000\n",
      "0.1194777128841086\n",
      "60000\n",
      "0.119613321957053\n",
      "70000\n",
      "0.11910450314758046\n",
      "80000\n",
      "0.11953357783234969\n",
      "90000\n",
      "0.12031632283599615\n",
      "100000\n",
      "0.12014730607336503\n",
      "110000\n",
      "0.12038081076240482\n",
      "120000\n",
      "0.12052037711512295\n",
      "130000\n",
      "0.12033482431127475\n",
      "140000\n",
      "0.12050585591252275\n",
      "150000\n",
      "0.12078569984371915\n",
      "160000\n",
      "0.12089067519883538\n",
      "170000\n",
      "0.1209608444750801\n",
      "180000\n",
      "0.1208355358198804\n",
      "190000\n",
      "0.12109868428569842\n",
      "0.12112854531983085\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "results = pd.DataFrame({'srch_id': X_test.srch_id, 'predicted': y_pred, 'actual' : y_test})\n",
    "eval_score = eval_ndcg(results, 'srch_id', 'predicted', 'actual')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
